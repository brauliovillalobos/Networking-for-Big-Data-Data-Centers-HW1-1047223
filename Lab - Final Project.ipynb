{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a25a92d",
   "metadata": {},
   "source": [
    "# Importing the useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f418ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from os import system as cmd\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Process, Manager\n",
    "import multiprocessing as mp\n",
    "\n",
    "import pyshark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "#simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a81e81",
   "metadata": {},
   "source": [
    "# Reading the .pcap file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c37b1",
   "metadata": {},
   "source": [
    "In our current directory, we have only one .pcap file and we want to access that file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15aa0327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name:           ./Final_project_file.pcap\n",
      "File type:           Wireshark/... - pcapng\n",
      "File encapsulation:  Ethernet\n",
      "File timestamp precision:  microseconds (6)\n",
      "Packet size limit:   file hdr: (not set)\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Number of packets:   5,000 k\n",
      "File size:           490 MB\n",
      "Data size:           5,991 MB\n",
      "Capture duration:    17.557630 seconds\n",
      "First packet time:   2019-04-10 07:00:00.056001\n",
      "Last packet time:    2019-04-10 07:00:17.613631\n",
      "Data byte rate:      341 MBps\n",
      "Data bit rate:       2,729 Mbps\n",
      "Average packet size: 1198.22 bytes\n",
      "Average packet rate: 284 kpackets/s\n",
      "SHA256:              17c90cad2fbbde982d4285e4698e2ed6c88999955861894385a1613a7b7997a3\n",
      "RIPEMD160:           fc1047598207dfb1e98c2b720f6a30ae31287066\n",
      "SHA1:                968263edd2013c098fa12f906233edb7d3aa1705\n",
      "Strict time order:   False\n",
      "Capture application: Editcap (Wireshark) 3.4.2 (Git v3.4.2 packaged as 3.4.2-1~ubuntu16.04.0+wiresharkdevstable1)\n",
      "Number of interfaces in file: 1\n",
      "Interface #0 info:\n",
      "                     Encapsulation = Ethernet (1 - ether)\n",
      "                     Capture length = 96\n",
      "                     Time precision = microseconds (6)\n",
      "                     Time ticks per second = 1000000\n",
      "                     Number of stat entries = 0\n",
      "                     Number of packets = 5000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It will produce a list of all of the files with .pcap extension\n",
    "list_pcap_file = glob.glob(\"./*.pcap\")\n",
    "\n",
    "# As we have only one .pcap file we want to access that file\n",
    "file = list_pcap_file[0]\n",
    "\n",
    "# Here we will show the general info about this file \n",
    "cmd(\"capinfos \"+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487728c",
   "metadata": {},
   "source": [
    "# Extracting general info of the .pcap file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd18192",
   "metadata": {},
   "source": [
    "Here we are asked to only extract 1 million of the packets and give some general info about that 1 million records. So first we will extract these packets and then we will give some general information about those extracted packets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d796e5",
   "metadata": {},
   "source": [
    "## Filtering 1 million records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3af95c",
   "metadata": {},
   "source": [
    "As we are asked to work on only 1 million of the packets, we will __create a directory name 'Splitted_1m'__ and split the original .pcap file to 5 different .pcap file __each one consisting 1 million__ of the packets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c79b6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The splitting process has been completed!!!\n"
     ]
    }
   ],
   "source": [
    "# The floder that will contain the splitted files\n",
    "One_million_path = \"Splitted_1m\"\n",
    "\n",
    "# Number of the packets in each file \n",
    "Limit_of_splitting = 1000000\n",
    "\n",
    "# Check if the directory is already there\n",
    "if os.path.isdir(One_million_path): \n",
    "\n",
    "    # If the directory is there, remove the whole directory\n",
    "    shutil.rmtree(One_million_path)\n",
    "\n",
    "# Create the directory to save the .pickle files \n",
    "os.mkdir(One_million_path)\n",
    "\n",
    "# Creating multiple files from the original file each one consisting 1m packets. \n",
    "cmd(f'editcap -c {Limit_of_splitting} {file} {One_million_path}/{Limit_of_splitting}.pcap')\n",
    "print('The splitting process has been completed!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07879620",
   "metadata": {},
   "source": [
    "Then we will pick the first file that is containing 1m of the packets and give the general info related to the packet in that file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5275cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Splitted_1m/1000000_00000_20190410070000.pcap'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pcap_file = glob.glob(\"Splitted_1m/*.pcap\")\n",
    "\n",
    "# As we have only one .pcap file we want to access that file\n",
    "file = list_pcap_file[0]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1745955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of packets in the capture: \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Number of packets:   1,000 k\n",
      "--------------------------------------------------\n",
      "\n",
      "The average data rate (bit/sec):\n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Data bit rate:       2,419 Mbps\n",
      "--------------------------------------------------\n",
      "\n",
      "The average packet size: \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Average packet size: 1099.84 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "The start time of the capture: \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "First packet time:   2019-04-10 07:00:00.056001\n",
      "--------------------------------------------------\n",
      "\n",
      "Total length of all of the packets in the file (in bytes): \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Data size:           1,099 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "The end time of the capture: \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Last packet time:    2019-04-10 07:00:03.693100\n",
      "--------------------------------------------------\n",
      "\n",
      "The size of the file (in bytes): \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "File size:           98 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "The average packet rate (packets/sec): \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Average packet rate: 274 kpackets/s\n",
      "--------------------------------------------------\n",
      "\n",
      "The average data rate (bytes/sec): \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Data byte rate:      302 MBps\n",
      "--------------------------------------------------\n",
      "\n",
      "General info about the capture: \n",
      "\n",
      "File name:           Splitted_1m/One_million_00000_20190410070000.pcap\n",
      "File type:           Wireshark/... - pcapng\n",
      "File encapsulation:  Ethernet\n",
      "File timestamp precision:  microseconds (6)\n",
      "Packet size limit:   file hdr: (not set)\n",
      "Packet size limit:   inferred: 34 bytes - 96 bytes (range)\n",
      "Number of packets:   1,000 k\n",
      "File size:           98 MB\n",
      "Data size:           1,099 MB\n",
      "Capture duration:    3.637099 seconds\n",
      "First packet time:   2019-04-10 07:00:00.056001\n",
      "Last packet time:    2019-04-10 07:00:03.693100\n",
      "Data byte rate:      302 MBps\n",
      "Data bit rate:       2,419 Mbps\n",
      "Average packet size: 1099.84 bytes\n",
      "Average packet rate: 274 kpackets/s\n",
      "SHA256:              0cd5fd34ddec92a3ea2072d102cc125c6a91bccc9f99e782dc9474f042f9b176\n",
      "RIPEMD160:           b60314ed2d84263202ef3012d196be7820c0cea7\n",
      "SHA1:                16bb7fe63a5a4a37e1d9b0cab842ab9af17655ac\n",
      "Strict time order:   False\n",
      "Capture application: Editcap (Wireshark) 3.4.2 (Git v3.4.2 packaged as 3.4.2-1~ubuntu16.04.0+wiresharkdevstable1)\n",
      "Number of interfaces in file: 1\n",
      "Interface #0 info:\n",
      "                     Encapsulation = Ethernet (1 - ether)\n",
      "                     Capture length = 96\n",
      "                     Time precision = microseconds (6)\n",
      "                     Time ticks per second = 1000000\n",
      "                     Number of stat entries = 0\n",
      "                     Number of packets = 1000000\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of packets in the capture: \\n\")\n",
    "# Number of the packets in the capture --> -c\n",
    "cmd(\"capinfos -c \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('The average data rate (bit/sec):\\n')\n",
    "# Average data rate, in bit/sec --> -i\n",
    "cmd(\"capinfos -i \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print(\"The average packet size: \\n\")\n",
    "# Average packet size --> -z\n",
    "cmd(\"capinfos -z \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('The start time of the capture: \\n')\n",
    "# Start time of the capture --> -a\n",
    "cmd(\"capinfos -a \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('Total length of all of the packets in the file (in bytes): \\n')\n",
    "# Total length of all of the packets in the file, in bytes --> d\n",
    "cmd(\"capinfos -d \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print(\"The end time of the capture: \\n\")\n",
    "# The end time of the capture --> -e\n",
    "cmd(\"capinfos -e \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('The size of the file (in bytes): \\n')\n",
    "# The size of the file, in bytes --> -s\n",
    "cmd(\"capinfos -s \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('The average packet rate (packets/sec): \\n')\n",
    "# The average packet rate, in packets/sec --> x\n",
    "cmd(\"capinfos -x \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('The average data rate (bytes/sec): \\n')\n",
    "# The average data rate, in bytes/sec ---> y\n",
    "cmd(\"capinfos -y \"+file)\n",
    "print('-' * 50, end = '\\n\\n')\n",
    "\n",
    "print('General info about the capture: \\n')\n",
    "# Capture duration --> -S\n",
    "cmd(\"capinfos \"+file)\n",
    "print('-' * 50, end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411b53d",
   "metadata": {},
   "source": [
    "# Extracting the packets info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021a543",
   "metadata": {},
   "source": [
    "Here we want to extract the information of the packets in the .pcap file and analyze the time taken to extract these information in __Sequential and Parallel reading__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f88eb",
   "metadata": {},
   "source": [
    "## Extract packet info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c91e5",
   "metadata": {},
   "source": [
    "Here we will write a function that will extract the desired info from the packets that are in .pcap file that we have passed to it and writes the produced dataframe in a pickle file to the passed directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21bc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_packet_info(file_name, path_to_save):\n",
    "    \n",
    "    # The information that we want to get from the packets\n",
    "    Columns = [\"Label DSCP\", \"header len\", \"ds_field\",\"ds_field_ecn\", \"length\", \n",
    "          \"Protocol\" ,\"flag_df\", \"flag_mf\", \"flag_rb\", \"fragment_offset\", \"ttl\", \n",
    "          \"IP_SRC\", \"IP_DST\",\"src_port\", \"dst_port\",\"time\"] \n",
    "    \n",
    "    # This dataframe will contain the features of all of the packets in the given file\n",
    "    Packet_info_df = pd.DataFrame(columns = Columns)\n",
    "    \n",
    "    # We will read the .pcap file \n",
    "    pcap = pyshark.FileCapture(file_name)\n",
    "\n",
    "    # We will go through the packets in the .pcap file \n",
    "    for packet in pcap:\n",
    "        \n",
    "        # For each packet we will create a dictionary to store the features of the packet \n",
    "        Packet_info = dict()\n",
    "        \n",
    "        # We will only extract the features of the IP packets\n",
    "        if 'IP' in packet :\n",
    "            \n",
    "            # Getting the value of the dsfield\n",
    "            Packet_info['Label DSCP'] = packet.ip.dsfield_dscp\n",
    "            \n",
    "            # The length of the IP header\n",
    "            Packet_info['header len'] = packet.ip.hdr_len\n",
    "    \n",
    "            # Differentiated Service\n",
    "            Packet_info['ds_field'] = int(packet.ip.dsfield,16)\n",
    "            \n",
    "            #Explicit Congestion Notification\n",
    "            Packet_info['ds_field_ecn'] = packet.ip.dsfield_ecn\n",
    "            \n",
    "            #Length of the Packet including the header\n",
    "            Packet_info['length'] = packet.ip.len\n",
    "            \n",
    "            #Number of Protocol (e.g. 6 = TCP, 17 = UDP, 1 = ICMP)\n",
    "            Packet_info['Protocol'] = packet.ip.proto\n",
    "            \n",
    "            #Flag Do not Fragment \n",
    "            Packet_info['flag_df'] = packet.ip.flags_df\n",
    "            \n",
    "            #Flag More Fragment\n",
    "            Packet_info['flag_mf'] = packet.ip.flags_mf\n",
    "            \n",
    "            #Flag Reserved - Must be 0\n",
    "            Packet_info['flag_rb'] = packet.ip.flags_rb \n",
    "            \n",
    "            #Fragment Offset\n",
    "            Packet_info['fragment_offset'] = packet.ip.frag_offset\n",
    "        \n",
    "            #Time To Live\n",
    "            Packet_info['ttl'] = packet.ip.ttl\n",
    "            \n",
    "            #### Extraction of the Ip Source and Ip Destination###\n",
    "            Packet_info['IP_SRC'] = packet.ip.src\n",
    "            Packet_info['IP_DST'] = packet.ip.dst\n",
    "            \n",
    "            #### Extraction of the Port ####\n",
    "            if \"UDP\" in packet:\n",
    "                Packet_info['src_port'] = packet.udp.srcport\n",
    "                Packet_info['dst_port'] = packet.udp.dstport\n",
    "                \n",
    "            elif \"TCP\" in packet :\n",
    "                Packet_info['src_port'] = packet.tcp.srcport\n",
    "                Packet_info['dst_port'] = packet.tcp.dstport\n",
    "                \n",
    "            else:\n",
    "                #Protocol as IP and ICMP e Ws.Short Port in src and dst will be set to -1\n",
    "                Packet_info['src_port'] = -1\n",
    "                Packet_info['dst_port'] = -1\n",
    "\n",
    "            # The time that this packet has been sniffed\n",
    "            Packet_info['time'] = float(packet.sniff_timestamp)\n",
    "            \n",
    "            # Adding this new packet to the passed dataframe\n",
    "            Packet_info_df = Packet_info_df.append(Packet_info, ignore_index = True)\n",
    "    \n",
    "    # We just want to keep the name of the file and not the path \n",
    "    file_name = file_name.split('/')[-1]\n",
    "    \n",
    "    # Write the dataframe to a .pickle file for the faster reading later\n",
    "    Packet_info_df.to_pickle(path_to_save + '/' + file_name.split('.')[0] + '.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226d025",
   "metadata": {},
   "source": [
    "## Sequential Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf6023",
   "metadata": {},
   "source": [
    "In the sequential reading we want to go through file that is containing 1 million records and extract the features of the packets in the .pcacp file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49faa63c",
   "metadata": {},
   "source": [
    "In the sequential reading, we will send the whole file to the function in order the extract the features for each of the packets in the capture. We will save the result in a pickle file in __'Sequential_reading_pickle'__ directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28030880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the directory that we will store the .pickle file for sequential reading\n",
    "Sequential_reading_path = 'Sequential_reading_pickle'\n",
    "\n",
    "# Check if the directory is already there\n",
    "if os.path.isdir(Sequential_reading_path): \n",
    "\n",
    "    # If the directory is there, remove the whole directory\n",
    "    shutil.rmtree(Sequential_reading_path)\n",
    "\n",
    "# Create the directory to save the .pickle files \n",
    "os.mkdir(Sequential_reading_path)\n",
    "\n",
    "# Start time of calling the function \n",
    "start_time = time.time()\n",
    "\n",
    "# Calling the function to extract the features of the packets\n",
    "Extract_packet_info(file, Sequential_reading_path)\n",
    "\n",
    "# End time of processing the packets\n",
    "Sequential_time = (time.time() - start_time)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f'Time taken to extract the features of the packets: {\"{:.2f}\".format(Sequential_time)} seconds')\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25101c2f",
   "metadata": {},
   "source": [
    "Reading the dataframe after sequential reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b46678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label DSCP</th>\n",
       "      <th>header len</th>\n",
       "      <th>ds_field</th>\n",
       "      <th>ds_field_ecn</th>\n",
       "      <th>length</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>flag_df</th>\n",
       "      <th>flag_mf</th>\n",
       "      <th>flag_rb</th>\n",
       "      <th>fragment_offset</th>\n",
       "      <th>ttl</th>\n",
       "      <th>IP_SRC</th>\n",
       "      <th>IP_DST</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>793</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label DSCP header len ds_field ds_field_ecn length Protocol flag_df flag_mf  \\\n",
       "0          0         20        0            0    793       17       1       0   \n",
       "1          0         20        0            0     60       17       1       0   \n",
       "2          0         20        0            0     61       17       1       0   \n",
       "3          0         20        0            0    116       17       1       0   \n",
       "4          0         20        0            0     54       17       1       0   \n",
       "5          0         20        0            0     67       17       1       0   \n",
       "6          0         20        0            0     61       17       1       0   \n",
       "\n",
       "  flag_rb fragment_offset  ttl          IP_SRC          IP_DST src_port  \\\n",
       "0       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "1       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "2       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "3       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "4       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "5       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "6       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "\n",
       "  dst_port          time  \n",
       "0      443  1.619450e+09  \n",
       "1    50688  1.619450e+09  \n",
       "2      443  1.619450e+09  \n",
       "3    50688  1.619450e+09  \n",
       "4    50688  1.619450e+09  \n",
       "5      443  1.619450e+09  \n",
       "6      443  1.619450e+09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pickle_files_seq = glob.glob(Sequential_reading_path+ '/*.pickle')\n",
    "All_packet_info_df = pd.read_pickle(Pickle_files_seq[0])\n",
    "All_packet_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf52c8",
   "metadata": {},
   "source": [
    "## Parallel Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf9402",
   "metadata": {},
   "source": [
    "In the parallel reading we will split the file into more than one file and retrieve the feature of the packets in parallel. In our case as we should work with 1 million packets we will split this file into 5 files each one consisting of 200,000 packets and extract the packets features in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8feb562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files have been created at: 'Parallel_splitting\\'\n"
     ]
    }
   ],
   "source": [
    "file = 'pcap_trial.pcap'\n",
    "\n",
    "# The number of the packets that should be in one file \n",
    "Limit_of_splitting = 1500\n",
    "\n",
    "# The directory that will contain the splitted .pcap files\n",
    "Parallel_splitting_path = \"Parallel_splitting\"\n",
    "    \n",
    "# Check if the directory is already there\n",
    "if os.path.isdir(Parallel_splitting_path): \n",
    "\n",
    "    # If the directory is there, remove the whole directory\n",
    "    shutil.rmtree(Parallel_splitting_path)\n",
    "\n",
    "# Create the directory to save the .pickle files \n",
    "os.mkdir(Parallel_splitting_path)\n",
    "\n",
    "# Creating multiple files from the original file each one consisting 1m packets. \n",
    "cmd(f'editcap -c {Limit_of_splitting} {file} {Parallel_splitting_path}/{Limit_of_splitting}.pcap')\n",
    "\n",
    "print(f'The files have been created at: \\'{Parallel_splitting_path}\\\\\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6ef1a",
   "metadata": {},
   "source": [
    "After splitting the files we will call the function to extract the packets' information for each file and save the result in the .pickle files to be aggregated in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc9cce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file 0\n",
      "Working on file 1\n",
      "Working on file 2\n",
      "Working on file 3\n",
      "Working on file 4\n",
      "Working on file 5\n",
      "Working on file 6\n",
      "Working on file 7\n",
      "Please wait for the end of the processes !!!\n",
      "<Process name='Process-2' pid=16369 parent=16290 started>\n",
      "<Process name='Process-3' pid=16371 parent=16290 stopped exitcode=0>\n",
      "<Process name='Process-4' pid=16373 parent=16290 stopped exitcode=0>\n",
      "<Process name='Process-5' pid=16374 parent=16290 stopped exitcode=0>\n",
      "<Process name='Process-6' pid=16375 parent=16290 stopped exitcode=0>\n",
      "<Process name='Process-7' pid=16376 parent=16290 started>\n",
      "<Process name='Process-8' pid=16378 parent=16290 stopped exitcode=0>\n",
      "<Process name='Process-9' pid=16384 parent=16290 stopped exitcode=0>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Parallel_reading_pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16290/1836216264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m### Finish ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'All .pickle files have been created at \\'{Parallel_reading_pickle}\\\\\\''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mtime_parallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_parallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Parallel_reading_pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# The path to save the pickle file for each of the splitted files \n",
    "Parallel_reading_path = 'Parallel_reading_pickle'\n",
    "\n",
    "# Check if the directory is already there\n",
    "if os.path.isdir(Parallel_reading_path): \n",
    "\n",
    "    # If the directory is there, remove the whole directory\n",
    "    shutil.rmtree(Parallel_reading_path)\n",
    "\n",
    "# Create the directory to save the .pickle files \n",
    "os.mkdir(Parallel_reading_path)\n",
    "\n",
    "#Instantiate the manager\n",
    "manager = Manager()\n",
    "\n",
    "#Start measuring time\n",
    "start_time = time.time()\n",
    "\n",
    "#-----------------------Files-----------------------\n",
    "# It will produce a list of all of the files with .pcap extension\n",
    "list_pcap_file = glob.glob(f'{Parallel_splitting_path}/*.pcap')\n",
    "\n",
    "#Vect to store results\n",
    "lista_process = []\n",
    "\n",
    "for file_index, file in enumerate(list_pcap_file):\n",
    "    print(f'Working on file {file_index}')\n",
    "\n",
    "    # Send the file f\n",
    "    p1 = Process(target = Extract_packet_info, args = (file, Parallel_reading_path))\n",
    "\n",
    "    lista_process.append(p1)\n",
    "\n",
    "    p1.start()\n",
    "\n",
    "print('Please wait for the end of the processes !!!')\n",
    "for process in lista_process:\n",
    "    print(process)\n",
    "    process.join()\n",
    "\n",
    "    \n",
    "### Finish ####\n",
    "\n",
    "print(f'All .pickle files have been created at \\'{Parallel_reading_path}\\\\\\'')\n",
    "time_parallel = (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" % (time_parallel)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f30cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the pickle files \n",
    "Pickle_merged = pd.concat([pd.read_pickle(pickle_file) for pickle_file in glob.glob(f'{Parallel_reading_path}/*.pickle')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4273d015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label DSCP</th>\n",
       "      <th>header len</th>\n",
       "      <th>ds_field</th>\n",
       "      <th>ds_field_ecn</th>\n",
       "      <th>length</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>flag_df</th>\n",
       "      <th>flag_mf</th>\n",
       "      <th>flag_rb</th>\n",
       "      <th>fragment_offset</th>\n",
       "      <th>ttl</th>\n",
       "      <th>IP_SRC</th>\n",
       "      <th>IP_DST</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>793</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label DSCP header len ds_field ds_field_ecn length Protocol flag_df flag_mf  \\\n",
       "0          0         20        0            0    793       17       1       0   \n",
       "1          0         20        0            0     60       17       1       0   \n",
       "0          0         20        0            0     61       17       1       0   \n",
       "0          0         20        0            0     54       17       1       0   \n",
       "1          0         20        0            0     67       17       1       0   \n",
       "0          0         20        0            0     61       17       1       0   \n",
       "1          0         20        0            0    116       17       1       0   \n",
       "\n",
       "  flag_rb fragment_offset  ttl          IP_SRC          IP_DST src_port  \\\n",
       "0       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "1       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "0       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "0       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "1       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "0       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "1       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "\n",
       "  dst_port          time  \n",
       "0      443  1.619450e+09  \n",
       "1    50688  1.619450e+09  \n",
       "0      443  1.619450e+09  \n",
       "0    50688  1.619450e+09  \n",
       "1      443  1.619450e+09  \n",
       "0      443  1.619450e+09  \n",
       "1    50688  1.619450e+09  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pickle_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69df516",
   "metadata": {},
   "source": [
    "# 3) Extract the IP which generates the highest amount of sender traffic, evaluate the bit rate (0.1 sec) for the 6 IP addresses mostly used as endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40cd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a11dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37786ae7",
   "metadata": {},
   "source": [
    "# 4) Top 5 Destination IP (received bytes) and Top 5 Source IP (sent bytes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57bc4469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label DSCP</th>\n",
       "      <th>header len</th>\n",
       "      <th>ds_field</th>\n",
       "      <th>ds_field_ecn</th>\n",
       "      <th>length</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>flag_df</th>\n",
       "      <th>flag_mf</th>\n",
       "      <th>flag_rb</th>\n",
       "      <th>fragment_offset</th>\n",
       "      <th>ttl</th>\n",
       "      <th>IP_SRC</th>\n",
       "      <th>IP_DST</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>793</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>443</td>\n",
       "      <td>50688</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192.168.43.28</td>\n",
       "      <td>142.250.180.78</td>\n",
       "      <td>50688</td>\n",
       "      <td>443</td>\n",
       "      <td>1.619450e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label DSCP header len ds_field ds_field_ecn length Protocol flag_df flag_mf  \\\n",
       "0          0         20        0            0    793       17       1       0   \n",
       "1          0         20        0            0     60       17       1       0   \n",
       "2          0         20        0            0     61       17       1       0   \n",
       "3          0         20        0            0    116       17       1       0   \n",
       "4          0         20        0            0     54       17       1       0   \n",
       "5          0         20        0            0     67       17       1       0   \n",
       "6          0         20        0            0     61       17       1       0   \n",
       "\n",
       "  flag_rb fragment_offset  ttl          IP_SRC          IP_DST src_port  \\\n",
       "0       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "1       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "2       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "3       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "4       0               0   53  142.250.180.78   192.168.43.28      443   \n",
       "5       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "6       0               0  128   192.168.43.28  142.250.180.78    50688   \n",
       "\n",
       "  dst_port          time  \n",
       "0      443  1.619450e+09  \n",
       "1    50688  1.619450e+09  \n",
       "2      443  1.619450e+09  \n",
       "3    50688  1.619450e+09  \n",
       "4    50688  1.619450e+09  \n",
       "5      443  1.619450e+09  \n",
       "6      443  1.619450e+09  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Columns = [\"Label DSCP\", \"header len\", \"ds_field\",\"ds_field_ecn\", \"length\", \n",
    "          \"Protocol\" ,\"flag_df\", \"flag_mf\", \"flag_rb\", \"fragment_offset\", \"ttl\", \n",
    "          \"IP_SRC\", \"IP_DST\",\"src_port\", \"dst_port\",\"time\"] \n",
    "Packets_info = pd.DataFrame(columns = Columns)\n",
    "Extract_packet_info('small_pcap_trial.pcap', Packets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f2a06d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label DSCP</th>\n",
       "      <th>header len</th>\n",
       "      <th>ds_field</th>\n",
       "      <th>ds_field_ecn</th>\n",
       "      <th>length</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>flag_df</th>\n",
       "      <th>flag_mf</th>\n",
       "      <th>flag_rb</th>\n",
       "      <th>fragment_offset</th>\n",
       "      <th>ttl</th>\n",
       "      <th>IP_SRC</th>\n",
       "      <th>IP_DST</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Label DSCP, header len, ds_field, ds_field_ecn, length, Protocol, flag_df, flag_mf, flag_rb, fragment_offset, ttl, IP_SRC, IP_DST, src_port, dst_port, time]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Packets_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cff7141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I'm working on: ./data_00000_20190410070000.pcap\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/tvlrdwhj03j_14qd1gqpsrm80000gn/T/ipykernel_8498/671339509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_Info_pckt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finish the reading part\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/sg/tvlrdwhj03j_14qd1gqpsrm80000gn/T/ipykernel_8498/2346925620.py\u001b[0m in \u001b[0;36mextract_Info_pckt\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtotal_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpacket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpcap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m### MAC Address verification ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyshark/capture/capture.py\u001b[0m in \u001b[0;36m_packets_from_tshark_sync\u001b[0;34m(self, packet_count, existing_process)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# NOTE: This has code duplication with the async version, think about how to solve this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mtshark_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexisting_process\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tshark_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mpsml_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_psml_struct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtshark_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mpackets_captured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \"\"\"\n\u001b[1;32m    591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "dataFrame = extract_Info_pckt(file_name)\n",
    "print(\"Finish the reading part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a3a785",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/tvlrdwhj03j_14qd1gqpsrm80000gn/T/ipykernel_8498/2122872359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Save the dataframe in a pickle format, in this way once we saved it we can just reload without losing time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PacketDataframe.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error message - Data created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "#Save the dataframe in a pickle format, in this way once we saved it we can just reload without losing time\n",
    "dataFrame.to_pickle(\"PacketDataframe.pkl\")\n",
    "\n",
    "sys.exit(\"Error message - Data created\")\n",
    "\n",
    "#Comment here once created dataset\n",
    "\n",
    "#Reload dataframe\n",
    "dataFrame = pd.read_pickle(\"PacketDataframe.pkl\")\n",
    "\n",
    "print(\"Dataframe overview: \\n\")\n",
    "print(dataFrame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574382a6",
   "metadata": {},
   "source": [
    "# 5) Evaluate bitRate considering all the trace with 3 different sampling rate;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7cff5e",
   "metadata": {},
   "source": [
    "# 6) GeoLocal Referenciation of the 5 sessions with the highest amount of traffic generated;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b9def",
   "metadata": {},
   "source": [
    "# 7) 10 Protocol mostly used;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34422d9d",
   "metadata": {},
   "source": [
    "# 8) Port Scanner evaluation (10 Ports mostly used);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e60b09",
   "metadata": {},
   "source": [
    "# 9) InterArrival Time boxplot between TCP and UDP Sessions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494df8f1",
   "metadata": {},
   "source": [
    "# 10) Develop your own analysis (e.g. Topology of the network using networkx or evaluation about a variable such as TTL) (BONUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb9d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
